# ğŸ§  AgentForge

**AgentForge** is a modular AI observability toolkit designed to trace, debug, and evaluate LLM agent runs step-by-step.  
This project helps developers build reliable, transparent multi-agent workflows by enabling trace visualization, memory inspection, and failure simulation.

---

## âœ… Week 1 Scope: Core Trace Infrastructure

### ğŸš€ Features Built

- âœ… Gemini-powered agent (via LangChain)
- âœ… Tool usage logging (e.g., Wikipedia tool)
- âœ… Step-by-step trace output in JSON format
- âœ… Streamlit dashboard to visualize:
  - Agent metadata
  - Tool inputs and outputs
  - Memory hits (RAG chunks)
- âœ… Failure case templates:
  - Hallucination
  - Tool misuse
  - Irrelevant memory
  - Skipped tools
- âœ… Prompt evaluation script with manual scoring

---

## ğŸ› ï¸ How to Run

### 1. ğŸ“¦ Install Dependencies

```bash
pip install streamlit langchain langchain-google-genai langsmith wikipedia
```
### 2. ğŸ”‘ Set Gemini API Key
``` bash 
export GOOGLE_API_KEY=your_api_key_here  # or set in Python
```

### 3. â–¶ï¸ Run the Streamlit Dashboard
``` bash 
streamlit run agentforge_dashboard.py
```

### 4. ğŸ“ Upload a Trace
Upload any of the JSON files from /traces or /failures to visualize agent reasoning.


# ğŸ§­ Next Steps (Week 2 Preview)
- Agent Replay + Patch Mode

- Prompt A/B Testing Dashboard

- Automated Evaluation & Self-Fix Pipeline
